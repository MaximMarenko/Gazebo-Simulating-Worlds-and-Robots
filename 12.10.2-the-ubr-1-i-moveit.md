# 12.10.2 The UBR-1 и MoveIt!

Сотрудники компании Unbound Robotics опубликовали пакет настроек MoveIt! для UBR-1, чтобы мы могли попробовать некоторые из наших ранних скриптов ручной навигации. При работе с Pi Robot мы использовали RViz для визуализации сцены. На этот раз мы используем Gazebo.

Если у вас еще не запущена симуляция UBR-1, запустите ее сейчас:

```text
$ roslaunch ubr1_gazebo simulation.launch
```

Далее, запустите MoveIt! узлы для UBR-1:

```text
$ roslaunch ubr1_moveit move_group.launch
```

Теперь давайте попробуем обратную кинематику. Скрипт ubr1\_ik\_demo.py \(расположен в каталоге rbx2\_gazebo/scripts\) похож на наш предыдущий скрипт moveit\_ik\_demo.py. Новый скрипт не ссылается на именованные позиции \(например, "resting"\), которые были определены в конфигурации Pi Robot'а MoveIt!, так как эти позиции не определены в конфигурационном файле UBR-1 MoveIt!. Кроме того, скрипты используют группу конфигурации arm\_with\_torso в UBR-1, так что торсионный шарнир может быть включен в IK решение. Целевая поза, которую мы установили для захвата в сценарии, была бы слишком высокой для робота, чтобы дотянуться, если у него нет телескопического туловища, так что мы увидим, как полезно это сочетание может быть, и как легко MoveIt! включает сочетание в поиск решения.

Чтобы попробовать сценарий, выполните следующую команду, не спуская глаз с робота в Gazebo:

```text
$ rosrun rbx2_gazebo ubr1_ik_demo.py
```

Рука и туловище должны двигаться вверх, а захват принимает горизонтальную позицию, указывающую вперед.

Чтобы вернуть руку в исходное положение, воспользуйтесь скриптом UBR-1 tuck\_arm.py, входящим в пакет ubr1\_grasping:

```text
$ rosrun ubr1_grasping tuck_arm.py
```

Далее попробуем декартовый путь с помощью скрипта ubr1\_cartesian\_demo.py.

```text
$ rosrun rbx2_gazebo ubr1_cartesian_demo.py _cartesian:=true
```

Рука сначала должна двигаться не по декартовому пути к начальной конфигурации, определенной в скрипте. Следующая траектория должна перемещать захват вдоль декартового треугольника, заканчиваясь обратно в начальной позиции.

Наконец, давайте попробуем демо-версию. Демонстрация обеспечена ребятами из Unbounded Robotics и использует имитацию восприятия через 3D-камеру головы, чтобы подобрать маленький куб со столешницы и поместите его обратно на новое место. \(Если вы хотите покопаться в коде, чтобы посмотреть, как они сделали часть восприятия, посмотрите на C++ файлы в каталоге ubr1\_grasping/src. Например, файл _shape\_extraction.cpp_ вычисляет форму куба, лежащего на столе, используя библиотеку Point Cloud Library\).

Перед началом работы, завершите текущую сессию Gazebo, выбрав в меню "**Файл**" пункт "**Выход**", затем введя _Ctrl-C_ в терминал, используемый для запуска симуляции. Затем введите _Ctrl-C_ в терминале, который используется для запуска файла _move\_group.launch_.

Теперь начните новую симуляцию с помощью файла simulation\_grasping.launch:

```text
$ roslaunch ubr1_gazebo simulation_grasping.launch
```

На этот раз вы должны увидеть UBR-1 вместе со столом и кубом, как показано ниже:

![](.gitbook/assets/image%20%2811%29.png)

Далее, откройте узлы MoveIt! с помощью файла grasping.launch, который также запустит код восприятия, позволяющий смоделированной 3D камере визуально определить местонахождение куба на поверхности стола:

```text
$ roslaunch ubr1_grasping grasping.launch
```

Наконец, запустите демо-версию:

```text
$ rosrun ubr1_grasping pick_and_place.py --once
```

Если все пройдет хорошо, UBR-1 должен поднять куб своим захватом и положить его обратно на стол справа от робота. Обратите внимание, что успех операции не гарантирован, но, как правило, она будет выполнена с первой попытки.



