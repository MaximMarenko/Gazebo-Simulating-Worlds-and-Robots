# 12.11 Поднятие и Расположение с помощью UBR-1 Perception Pipeline

Один из аспектов поднятия и расположения, который мы еще не рассмотрели, - это сегментация визуальной сцены таким образом, чтобы робот знал, что захватить, как расположить и сориентировать свой захват относительно целевого объекта. Типичный подход заключается в использовании библиотеки [Point Cloud Library](https://pointclouds.org/) \(PCL\), как это сделано в пакете Майкла Фергюсона для управления роботом, играющим в шахматы, а также в пакете захвата UBR-1. Оба пакета используют C++ API для PCL, но можно также попробовать [Python-PCL-связки](https://github.com/strawlab/python-pcl).

Несмотря на то, что детали программирования процесса восприятия выходят за рамки этого тома, основная процедура выглядит следующим образом:

* подогнать плоскость к облаку точки камеры глубины, чтобы обнаружить поверхность опоры \(обычно столешницу\)
* удалить из облака точки, принадлежащие этой поверхности \(называемые "инсайдерами"\), так, чтобы оставшиеся точки соответствовали расположенным на поверхности объектам
* сгруппировать оставшиеся точки по кластерам на основе евклидового расстояния между точками
* подгонять к кластерам коробки или цилиндры и вычислять их позиции
* как только мы получаем позицию целевого объекта, вычисляем набор подходящих поз для захвата, как мы делали это ранее с виртуальной демонстрацией поднятия и размещения.

Обратите внимание, что эта техника вообще не использует RGB-изображение с камеры, поэтому теоретически метод будет работать даже в темноте.

Хотя для нашей демонстрации мы будем использовать код восприятия UBR-1, еще один полезный ресурс - это пакет [handle\_detector](http://wiki.ros.org/handle_detector), который использует данные 3D облака точек для поиска местоположения на объектах различной формы. Существует также пакет [moveit\_simple\_grasps ](http://wiki.ros.org/moveit_simple_grasps)для генерации поз захвата для различных примитивных форм, таких как коробки и цилиндры, а также упаковка [GraspIt!](http://wiki.ros.org/graspit), которая обрабатывает большое количество разнообразных форм. Для распознавания объектов можно попробовать [object recognition kitchen](http://wg-perception.github.io/object_recognition_core/), основанный на ecto.

Альтернативой обнаружению или распознаванию объектов на основе PCL является использование AR-тегов, о которых мы узнали в Главе 10. При таком подходе один или несколько тегов AR помещаются на объект, который должен быть захвачен, затем пакет _ar\_track\_alvar_ может быть использован для возврата позиции цели. Эта поза затем может быть использована более или менее непосредственно в нашем раннем скрипте _moveit\_pick\_and\_place\_demo.py_ в качестве отправной точки для генерации возможных поз захвата для захвата.



